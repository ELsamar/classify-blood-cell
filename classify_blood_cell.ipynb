{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\"> jupyter notebook solution</span> : classify blood cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">  Business Understanding :  </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important problem in blood diagnostics is classifying different types of blood cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <span style=\"color:blue\">  Import libraries :  </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries for data manipulation and visualization\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">  Load data : </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_test = np.load(\"image_test.npy\")\n",
    "image_train = np.load(\"image_train.npy\")\n",
    "target_train = np.load(\"target_train.npy\")\n",
    "target_test = np.load(\"target_test.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:blue\">   Perform a brief exploratory analysis : </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Data Understanding & Data requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\">  How many training,  testing examples do we have ? What shape are the images and target ? </p>\n",
    "\n",
    "<p style=\"color:blue\">What is the proportion of each observed target ? Are the datasets balanced ? </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_test[0][1][1])\n",
    "print (image_test.shape)\n",
    "print (image_train.shape)\n",
    "print (target_train.shape)\n",
    "print (target_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(image_train[0][1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(image_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy.ndarray to pandas.core.frame.DataFrame\n",
    "df_target_train = pd.DataFrame(target_train, \n",
    "             columns=['target_train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_target_train['target_train'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the target variable \n",
    "df_target_train['target_train'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the target variable\n",
    "import seaborn as sns\n",
    "g = sns.countplot(df_target_train['target_train'])\n",
    "g.set_xticklabels(['lymphocytes', 'neutrophils', 'monocytes', 'eosinophils',\n",
    "       'unknown'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\"> we can clearly see that there is a huge difference between the data set. \n",
    "296 neutrophils ,279 lymphocytes ,28 monocytes ,12 eosinophils and 2 unknown.  </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_counts = np.unique(target_train, return_counts = True)\n",
    "test_counts = np.unique(target_test, return_counts = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_names = ['lymphocytes', 'neutrophils', 'monocytes', 'eosinophils','unknown']\n",
    "pd.DataFrame({ \"train\": train_counts[1], \"test\": test_counts[1]}, index = class_names).plot.bar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(train_counts[1],\n",
    "        explode=(0, 0, 0, 0,0) , \n",
    "        labels=class_names,\n",
    "        autopct='%1.1f%%')\n",
    "plt.axis('equal')\n",
    "plt.title('Proportion of each observed category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\"> Imbalance Ratio (IR) :Is the proportion of the number of instances in the negative class to the number of instances in the positive one</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\">\n",
    "IR = (negative_class/positive_class)</p>\n",
    "<p style=\"color:blue\">\n",
    "Where positive_class is the number of minority class samples and negative_class is the number of majority class samples.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class count\n",
    "class_count_0, class_count_1,class_count_2, class_count_3 , class_count_4= df_target_train['target_train'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IR=(class_count_0+ class_count_1)/(class_count_2+ class_count_3 + class_count_4)\n",
    "IR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, you have 4 dimension to your input data (batch size, channels, height, width) you need to flatten out your images to two dimensions (number of images, channels* height* width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_train_reshape = image_train.reshape(1269,24*24*3)\n",
    "image_test_reshape = image_test.reshape(617,24*24*3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import linrary\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "xgb_model = XGBClassifier().fit(image_train_reshape, target_train)\n",
    "\n",
    "# predict\n",
    "xgb_y_predict = xgb_model.predict(image_test_reshape)\n",
    "\n",
    "# accuracy score\n",
    "xgb_score = accuracy_score(xgb_y_predict, target_test)\n",
    "\n",
    "print('Accuracy score is:', xgb_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\" >We can see 67% accuracy, we are getting very high accuracy because it is predicting mostly the majority class <p/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resampling Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\" > A widely adopted technique for dealing with highly unbalanced datasets is called resampling. It consists of removing samples from the majority class (under-sampling) and/or adding more examples from the minority class (over-sampling). <p/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Over Sampling Minority class by duplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "oversam = RandomOverSampler(sampling_strategy='minority')\n",
    "X_over,Y_over=oversam.fit_resample(image_train_reshape,target_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier().fit(X_over,Y_over)\n",
    "\n",
    "# predict\n",
    "xgb_y_predict = xgb_model.predict(X_over)\n",
    "\n",
    "# accuracy score\n",
    "xgb_score = accuracy_score(xgb_y_predict, Y_over)\n",
    "\n",
    "print('Accuracy score is:', xgb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy.ndarray to pandas.core.frame.DataFrame\n",
    "df_Y_over = pd.DataFrame(Y_over, \n",
    "             columns=['Y_over'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the target variable\n",
    "import seaborn as sns\n",
    "g = sns.countplot(df_Y_over['Y_over'])\n",
    "g.set_xticklabels(['lymphocytes', 'neutrophils', 'monocytes', 'eosinophils',\n",
    "       'unknown'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Under-sampling majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "sam = RandomUnderSampler(random_state=0)\n",
    "image_train_under,target_train_under=sam.fit_resample(image_train_reshape,target_train)\n",
    "image_test_under,target_test_under=sam.fit_resample(image_test_reshape,target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy.ndarray to pandas.core.frame.DataFrame\n",
    "df_target_train_under = pd.DataFrame(target_train_under, \n",
    "             columns=['target_train_under'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the target variable\n",
    "import seaborn as sns\n",
    "g = sns.countplot(df_target_train_under['target_train_under'])\n",
    "g.set_xticklabels(['lymphocytes', 'neutrophils', 'monocytes', 'eosinophils',\n",
    "       'unknown'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier().fit(image_train_under,target_train_under)\n",
    "\n",
    "# predict\n",
    "xgb_y_predict = xgb_model.predict(image_test_under)\n",
    "\n",
    "# accuracy score\n",
    "xgb_score = accuracy_score(xgb_y_predict, target_test_under)\n",
    "\n",
    "print('Accuracy score is:', xgb_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_count_0, class_count_1,class_count_2, class_count_3 , class_count_4= df_target_train_under['target_train_under'].value_counts()\n",
    "IR=(class_count_0+ class_count_1)/(class_count_2+ class_count_3 + class_count_4)\n",
    "IR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examples of images in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['lymphocytes', 'neutrophils', 'monocytes', 'eosinophils','unknown']\n",
    "def display_examples(class_names, image_test, target_test):\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    fig.suptitle(\"Examples of images in the dataset\", fontsize=16)\n",
    "    for i in range(25):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(image_test[i], cmap=plt.cm.binary)\n",
    "        plt.xlabel(target_test[i])\n",
    "    plt.show()\n",
    "    \n",
    "display_examples(class_names, image_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot images from 3 samples of each class from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['lymphocytes', 'neutrophils', 'monocytes', 'eosinophils','unknown']\n",
    "def display_examples(class_names, image_train, target_train):\n",
    "    fig = plt.figure(figsize = (10,10))\n",
    "    #fig.suptitle(\"Examples of images in the dataset\", fontsize=16)\n",
    "    for j in range(5):\n",
    "        posClass=np.where(target_train == class_names[j])\n",
    "        print(\"----\"+class_names[j]+\"---\")\n",
    "        for i in range(3):\n",
    "            plt.subplot(5,5,i+1)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.grid(False)\n",
    "            plt.imshow(image_train[[z[i] for z in posClass][0]], cmap=plt.cm.binary)\n",
    "            plt.xlabel(target_train[[z[i] for z in posClass][0]])\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "display_examples(class_names, image_train, target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">  Train machine learning models : </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method #1: Grayscale Pixel Values as Features\n",
    "#pixel features\n",
    "\n",
    "features = np.reshape(image_test, (1066176))\n",
    "\n",
    "features.shape, features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"color:blue\"> we chose Random Forest and Support Vector machine as they can deal with great number of features. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=30, random_state=0)\n",
    "clf.fit(image_train_under,target_train_under)\n",
    "print(clf.score(image_test_under,target_test_under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(image_test_under)\n",
    "pred2 = clf.predict(image_train_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting Accuracy Score\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(\"Test accuracy\",accuracy_score(target_test_under, pred))\n",
    "print(\"Train accuracy\",accuracy_score(target_train_under,pred2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze accuracy using 5-fold cross validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "k-Fold Cross-Validation\n",
    "Cross-validation is a resampling procedure used to evaluate machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# evaluate a RandomForestClassifier model using k-fold cross-validation\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# prepare the cross-validation procedure\n",
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "# create model\n",
    "model = RandomForestClassifier(max_depth=30, random_state=0)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model, image_train_reshape,target_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train_under.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract single tree\n",
    "estimator = clf.estimators_[5]\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "# Export as dot file\n",
    "export_graphviz(estimator, out_file='tree.dot', \n",
    "                feature_names = None,\n",
    "                class_names = class_names,\n",
    "                rounded = True, proportion = False, \n",
    "                precision = 3, filled = True)\n",
    "\n",
    "# Convert to png using system command (requires Graphviz)\n",
    "from subprocess import call\n",
    "call(['dot', '-Tpng', 'tree.dot', '-o', 'tree.png', '-Gdpi=600'])\n",
    "\n",
    "# Display in jupyter notebook\n",
    "from IPython.display import Image\n",
    "Image(filename = 'tree.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotfile = open(\"test.dot\", 'w')\n",
    "tree.export_graphviz(modelTree, out_file=dotfile,\n",
    " feature_names = None,\n",
    "                class_names = class_names,\n",
    "filled=True, rounded=True,\n",
    "special_characters=True)\n",
    "\n",
    "dotfile.close()\n",
    "system(\"dot -Tpng test.dot -o dtree7.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename = 'dtree7.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import svm model\n",
    "from sklearn import svm\n",
    "\n",
    "#Create a svm Classifier\n",
    "cl = svm.SVC(kernel='linear') # Linear Kernel\n",
    "\n",
    "#Train the model using the training sets\n",
    "cl.fit(image_train_under,target_train_under)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = cl.predict(image_test_under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cl.score(image_test_under,target_test_under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Model Accuracy: how often is the classifier correct?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(target_test_under, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we got a classification rate of 80%, considered as very good accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:blue\">  Train a deep learning model : </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This model contains a sequence of five Conv blocks containing combinations of SeparableConv2D, BatchNormalization, MaxPooling and Dropout layers. The output of the final Conv block is flattened and followed by three Fully Connected (FC) layers each with its own Dropout layer. A final FC layer is added with four units and a softmax activation for multiclass classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_image,valid_image,train_target,valid_target = train_test_split(image_train, target_train, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import decomposition\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.applications.vgg16 import VGG16 \n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Sequential, Model \n",
    "from keras.applications import DenseNet201\n",
    "from keras.initializers import he_normal\n",
    "from keras.layers import Lambda, SeparableConv2D, BatchNormalization, Dropout, MaxPooling2D, Input, Dense, Conv2D, Activation, Flatten \n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "\n",
    "# First Conv block\n",
    "model1.add(Conv2D(16 , (3,3) , padding = 'same' , activation = 'relu' , input_shape = (120,120,3)))\n",
    "model1.add(Conv2D(16 , (3,3), padding = 'same' , activation = 'relu'))\n",
    "model1.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Second Conv block\n",
    "model1.add(SeparableConv2D(32, (3,3), activation = 'relu', padding = 'same'))\n",
    "model1.add(SeparableConv2D(32, (3,3), activation = 'relu', padding = 'same'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Third Conv block\n",
    "model1.add(SeparableConv2D(64, (3,3), activation = 'relu', padding = 'same'))\n",
    "model1.add(SeparableConv2D(64, (3,3), activation = 'relu', padding = 'same'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "# Forth Conv block\n",
    "model1.add(SeparableConv2D(128, (3,3), activation = 'relu', padding = 'same'))\n",
    "model1.add(SeparableConv2D(128, (3,3), activation = 'relu', padding = 'same'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model1.add(Dropout(0.2))\n",
    "\n",
    "# Fifth Conv block \n",
    "model1.add(SeparableConv2D(256, (3,3), activation = 'relu', padding = 'same'))\n",
    "model1.add(SeparableConv2D(256, (3,3), activation = 'relu', padding = 'same'))\n",
    "model1.add(BatchNormalization())\n",
    "model1.add(MaxPooling2D(pool_size = (2,2)))\n",
    "model1.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "# FC layer \n",
    "model1.add(Flatten())\n",
    "model1.add(Dense(units = 512 , activation = 'tanh'))\n",
    "model1.add(Dropout(0.7))\n",
    "model1.add(Dense(units = 128 , activation = 'tanh'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(units = 64 , activation = 'tanh'))\n",
    "model1.add(Dropout(0.3))\n",
    "\n",
    "# Output layer\n",
    "model1.add(Dense(units = 4 , activation = 'softmax'))\n",
    "\n",
    "# Compile\n",
    "model1.compile(optimizer = \"adam\" , loss = 'sparse_categorical_crossentropy' , metrics = ['accuracy'])\n",
    "model1.summary()\n",
    "\n",
    "# Implement callbacks \n",
    "checkpoint = ModelCheckpoint(filepath='best_model.hdf5', save_best_only=True, save_weights_only=False)\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3, verbose = 1, mode='min', restore_best_weights = True)\n",
    "learning_rate_reduction = ReduceLROnPlateau(\n",
    "    monitor = 'val_accuracy', \n",
    "    patience = 2, \n",
    "    verbose = 1, \n",
    "    factor = 0.3, \n",
    "    min_lr = 0.000001)\n",
    "\n",
    "# Train\n",
    "history1 = model1.fit(\n",
    "   train_images,train_target,\n",
    "    batch_size = 32, \n",
    "    epochs = 30, \n",
    "    validation_data=(val_images, val_target), \n",
    "    callbacks=[learning_rate_reduction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze accuracy using 5-fold cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyze accuracy using 5-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=5, random_state=1, shuffle=True)\n",
    "# evaluate model\n",
    "scores = cross_val_score(model1,  image_train_under,target_train_under, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (mean(scores), std(scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets evaluate the model on test data to find the loss and accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model1.evaluate(image_test_under,target_test_under)\n",
    "\n",
    "print(\"Loss of the model  is - test \", results[0])\n",
    "print(\"Accuracy of the model is - test\", results[1]*100, \"%\")\n",
    "\n",
    "\n",
    "results = model1.evaluate(image_train_under,target_train_under)\n",
    "\n",
    "print(\"Loss of the model  is - train \", results[0])\n",
    "print(\"Accuracy of the model is - train\", results[1]*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model1.predict(image_test_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the modelâ€™s result metrics on the test dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function plot matrix\n",
    "def plot_confusion_matrix (cm):\n",
    "    plt.figure(figsize = (10,10))\n",
    "    sns.heatmap(\n",
    "        cm, \n",
    "        cmap = 'Blues', \n",
    "        linecolor = 'black', \n",
    "        linewidth = 1, \n",
    "        annot = True, \n",
    "        fmt = '', \n",
    "        xticklabels = class_names, \n",
    "        yticklabels = class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN model\n",
    "cmCNN = confusion_matrix(target_test_under, predictions)\n",
    "cmCNN = pd.DataFrame(cmCNN, index = ['0', '1', '2', '3','4'], columns = ['0', '1', '2', '3','4'])\n",
    "cmCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "plot_confusion_matrix(cmCNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifierModel\n",
    "cmRan = confusion_matrix(target_test_under, pred)\n",
    "cmRan = pd.DataFrame(cmRan, index = ['0', '1', '2', '3','4'], columns = ['0', '1', '2', '3','4'])\n",
    "cmRan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cmRan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM model \n",
    "\n",
    "cmSVM = confusion_matrix(target_test_under, y_pred)\n",
    "cmSVM = pd.DataFrame(cmSVM, index = ['0', '1', '2', '3','4'], columns = ['0', '1', '2', '3','4'])\n",
    "cmSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cmSVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TPR, TNR, PPV, NPV \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion-matrix-terminologies for RandomForestClassifierModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "FP = cmRan.sum(axis=0) - np.diag(cmRan)  \n",
    "FN = cmRan.sum(axis=1) - np.diag(cmRan)\n",
    "TP = np.diag(cmRan)\n",
    "TN = cmRan.sum() - (FP + FN + TP)\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### confusion-matrix-terminologies for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "FP = cmCNN.sum(axis=0) - np.diag(cmCNN)  \n",
    "FN = cmCNN.sum(axis=1) - np.diag(cmCNN)\n",
    "TP = np.diag(cmCNN)\n",
    "TN = cmCNN.sum() - (FP + FN + TP)\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP) \n",
    "# Precision or positive predictive value\n",
    "PPV = TP/(TP+FP)\n",
    "# Negative predictive value\n",
    "NPV = TN/(TN+FN)\n",
    "# Fall out or false positive rate\n",
    "FPR = FP/(FP+TN)\n",
    "# False negative rate\n",
    "FNR = FN/(TP+FN)\n",
    "# False discovery rate\n",
    "FDR = FP/(TP+FP)\n",
    "\n",
    "# Overall accuracy\n",
    "ACC = (TP+TN)/(TP+FP+FN+TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
